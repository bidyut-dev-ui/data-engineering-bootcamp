# Weeks 25-26: Job Preparation

**Goal**: Translate your technical skills into a compelling resume and prepare for Data Engineer interviews at service-based companies.

## Week 25: Resume Building

### Objectives
1. Create ATS-friendly resume
2. Translate projects into professional experience
3. Quantify achievements
4. Tailor for service companies (TCS, Accenture, Capgemini)

### Materials
- `RESUME_GUIDE.md`: Complete resume writing guide
- `resume_template.docx`: ATS-friendly template (create this)
- `sample_bullets.md`: 50+ example bullet points

### Tasks

#### 1. Review the Guide
Read `RESUME_GUIDE.md` thoroughly. Pay attention to:
- How to frame projects as professional work
- Quantifying impact (numbers matter!)
- Keywords for ATS systems

#### 2. Draft Your Resume
Create your resume with these sections:
1. Header (Name, contact, LinkedIn)
2. Professional Summary (3-4 lines)
3. Technical Skills (organized by category)
4. Professional Experience / Projects
5. Education

#### 3. Translate Your Projects

**Example Transformation**:

❌ **Before**: "Built a data pipeline using Airflow"

✅ **After**: "Designed and implemented automated ETL pipeline using Apache 
Airflow to process 100K+ customer records daily, reducing manual processing 
time by 80% and improving data accuracy to 99.5%"

**Your Projects to Include**:
1. **Capstone Project** (Weeks 21-24)
   - Frame as: "Customer Analytics Platform"
   - Highlight: End-to-end system, ML integration, API development
   
2. **Data Warehouse** (Week 8)
   - Frame as: "E-commerce Data Warehouse"
   - Highlight: Star schema design, query optimization
   
3. **Predictive Service** (Week 20)
   - Frame as: "ML Model Deployment"
   - Highlight: FastAPI, Docker, production-ready

#### 4. Add Metrics
For each bullet point, add numbers:
- Records processed: "1M+ records daily"
- Performance: "Reduced query time by 60%"
- Accuracy: "Achieved 85% model accuracy"
- Uptime: "99.5% API availability"

#### 5. Get Feedback
- Use online resume checkers (Jobscan, Resume Worded)
- Ask for feedback in communities (Reddit r/resumes)
- Test with ATS scanners

## Week 26: Interview Preparation

### Objectives
1. Master common Data Engineer interview questions
2. Practice system design problems
3. Prepare behavioral answers
4. Build confidence

### Materials
- `INTERVIEW_QUESTIONS.md`: 26 common questions with answers
- `system_design_practice.md`: Practice problems
- `behavioral_prep.md`: STAR method examples

### Study Plan

#### Day 1-2: SQL & Databases
- Review questions 1-5 in INTERVIEW_QUESTIONS.md
- Practice writing queries on paper
- Explain concepts out loud

#### Day 3-4: Python & Data Processing
- Review questions 6-9
- Code common patterns (chunking, groupby, etc.)
- Explain trade-offs

#### Day 5-6: ETL & Airflow
- Review questions 10-13
- Draw DAG diagrams
- Explain your capstone pipeline

#### Day 7: Data Warehousing
- Review questions 14-16
- Draw star schema on whiteboard
- Explain normalization trade-offs

#### Day 8: APIs & ML
- Review questions 17-22
- Explain your FastAPI projects
- Discuss ML model deployment

#### Day 9-10: System Design & Behavioral
- Practice questions 23-26
- Use STAR method for behavioral
- Record yourself answering

### Mock Interview Practice

#### Technical Questions
Set a timer (5 minutes per question):
1. "How would you design an ETL pipeline for processing 1TB of data daily?"
2. "Optimize this slow query: SELECT * FROM orders WHERE date > '2024-01-01'"
3. "Explain how you would handle duplicate records in a data pipeline"

#### Behavioral Questions
Prepare 3-4 stories using STAR method:
1. A challenging technical problem you solved
2. A time you had to learn a new technology quickly
3. A disagreement with a team member
4. A project you're proud of

### Company Research

For each company you apply to:
1. Visit their website - understand their business
2. Check recent news/projects
3. Identify technologies they use
4. Prepare 2-3 questions to ask them

### Common Interview Formats

#### Service Companies (TCS, Accenture, etc.):
1. **Round 1**: HR screening (15-30 min)
   - Background, expectations, availability
   
2. **Round 2**: Technical (45-60 min)
   - SQL queries (live coding)
   - Python questions
   - ETL concepts
   
3. **Round 3**: Technical + Managerial (45-60 min)
   - System design
   - Past projects discussion
   - Behavioral questions
   
4. **Round 4**: HR (compensation, joining)

### Questions to Ask Them

**About the Role**:
- "What does a typical day look like for a Data Engineer here?"
- "What technologies does the team currently use?"
- "How is the team structured?"

**About Projects**:
- "Can you describe a recent project the team worked on?"
- "What are the biggest data challenges you're facing?"

**About Growth**:
- "What learning opportunities are available?"
- "How do you support professional development?"

## Practice Resources

### Online Platforms
1. **LeetCode** (SQL section) - Practice SQL queries
2. **HackerRank** (SQL, Python) - Coding practice
3. **Pramp** - Free mock interviews
4. **InterviewBit** - Data Engineering questions

### Books (Optional)
1. "Designing Data-Intensive Applications" - Martin Kleppmann
2. "The Data Warehouse Toolkit" - Ralph Kimball

## Final Checklist

### Resume
- [ ] ATS-friendly format
- [ ] No spelling/grammar errors
- [ ] Quantified achievements
- [ ] Keywords from job descriptions
- [ ] Saved as PDF

### Interview Prep
- [ ] Reviewed all 26 questions
- [ ] Practiced SQL queries
- [ ] Prepared 3-4 STAR stories
- [ ] Can explain all your projects
- [ ] Researched target companies

### Soft Skills
- [ ] Professional email setup
- [ ] LinkedIn profile updated
- [ ] Practiced explaining technical concepts simply
- [ ] Prepared questions to ask interviewers

## Expected Learning Outcomes
- ✅ Professional resume ready for applications
- ✅ Confidence in technical interviews
- ✅ Ability to explain projects clearly
- ✅ Understanding of interview process
- ✅ Ready to apply for Data Engineer roles
